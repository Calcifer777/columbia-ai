\section{Rational Agents}

\paragraph{Rational Agent} For each possible percept sequence, a
rational agent should select an action that is expected to
maximize its performance measure, given the evidence provided by
the percept sequence and whatever built-in knowledge the agent
has.

When we define a rational agent, we group these properties
under PEAS:
\begin{itemize}
  \item Performance
  \item Environment
  \item Actuators
  \item Sensors
\end{itemize}
the problem specification for the task environment.
The rational agent we want to design for this task environment
is the solution.

\subsection{Environment}

\begin{itemize}
  \item Fully observable (vs. partially observable): An agent’s
    sensors give it access to the complete state of the
    environment at each point in time.  
  \item Deterministic (vs.  stochastic): The next state of the 
    environment is completely determined by the current state 
    and the action executed by the agent. 
    (If the environment is deterministic except for
    the actions of other agents, then the environment is
    strategic) 
  \item Episodic (vs. sequential): The agent’s
    experience is divided into atomic ”episodes” (each episode
    consists of the agent perceiving and then performing a single
    action), and the choice of action in each episode depends
    only on the episode itself.
  \item Static (vs. dynamic): The environment is unchanged while 
    an agent is deliberating. (The environment is semi-dynamic
    if the environment itself does not change with the passage of
    time but the agent’s performance score does.)
  \item Discrete (vs. continuous): A limited number of distinct,
    clearly defined percepts and actions. E.g., checkers is an example of a discrete environment, while self-driving car evolves
    in a continuous one.
  \item Single agent (vs. multi-agent): An agent operating by itself
    in an environment.
  \item Known (vs. Unknown): The designer of the agent may or
    may not have knowledge about the environment makeup. If
    the environment is unknown the agent will need to know how
    it works in order to decide.
\end{itemize}

\subsection{Agents}

The following agents types are listed in order of generality.

\subsubsection{Simple reflex agents}
\begin{itemize}
  \item select an action based on the current state
    only ignoring the percept history
  \item Can only work if the environment is fully observable
  \item Do not consider the future consequences of the actions
\end{itemize}

\subsubsection{Model-based reflex agents}

\begin{itemize}
  \item Handle partial observability by keeping track of the part of the
    world it can’t see now.
  \item Internal state depending on the percept history (best guess).
  \item Model of the world based on how the world evolves 
    independently from the agent, and how the agent actions
    affects the world
\end{itemize}

\subsubsection{Goal-based agents}

\begin{itemize}
  \item Knowing the current state of the environment is not enough.
    The agent needs some goal information.
  \item Agent program combines the goal information with the
    environment model to choose the actions that achieve that
    goal.
  \item Flexible as knowledge supporting the decisions is
    explicitly represented and can be modified.
\end{itemize}

\subsubsection{Utility-based agents}

\begin{itemize}
  \item Sometimes achieving the desired goal is not enough. We
    may look for quicker, safer, cheaper trip to reach a
    destination.
  \item Agent happiness should be taken into consideration. We
    call it \textit{utility}.
  \item A utility function is the agent’s performance measure
  \item Because of the uncertainty in the world, a utility agent
    choses the action that maximizes the expected utility.
\end{itemize}

\subsubsection{Learning agents}

Four conceptual components:
\begin{itemize}
  \item Learning element: responsible for making improvements
  \item Performance element: responsible for selecting external
    actions. It is what we considered as agent so far.
  \item Critic: How well is the agent is doing w.r.t. a fixed
    performance standard.
  \item Problem generator: allows the agent to explore.
\end{itemize}

\subsection{Agent's organization}

\begin{itemize}
  \item Atomic Representation: Each state of the world is a
    blackbox that has no internal structure. 
  \item  Factored Representation: Each state has some
    attributevalue properties
  \item Structured Representation: Relationships between the
    objects of a state can be explicitly expressed. 
\end{itemize}
